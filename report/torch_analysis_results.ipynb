{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Torch Analysis Results\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-location: left\n",
        "    toc-depth: 2\n",
        "    toc-title: Contents\n",
        "    code-fold: false\n",
        "    echo: false\n",
        "---"
      ],
      "id": "12b5a990"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cats vs Dogs Image Classification\n"
      ],
      "id": "3dd7e904"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import re\n",
        "import os\n",
        "\n",
        "root_dir_re_match = re.findall(string=os.getcwd(), pattern=\"^.+CatClassifier\")[0]\n",
        "sys.path.append(os.path.join(root_dir_re_match, \"model\"))\n",
        "import cons\n",
        "\n",
        "import torch\n",
        "from model.torch.VGG16_pretrained import VGG16_pretrained"
      ],
      "id": "9e032473",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This project aims to create a model to classify cat and dog images. The data was sourced from the [dogs-vs-cats](https://www.kaggle.com/competitions/dogs-vs-cats/overview) Kaggle competition, and also from [freeimages.com](https://www.freeimages.com/) using a web scraper. Docker containers were used to deploy the application on an EC2 spot instances in order to scale up hardware and computation power. \n",
        "\n",
        "## Example Image\n",
        "\n",
        "![Random Image](torch/random_image.jpg)\n",
        "\n",
        "## Data Processing\n",
        "\n",
        "The images were resized to a uniform dimension prior to the modelling training phase. See example image processing below. \n",
        "\n",
        "![Generator Plot](torch/generator_plot.jpg)\n",
        "\n",
        "## VGG16 Model Architecture\n",
        "\n",
        "A pre-trained VGG CNN model with 16 layers was trained using the processed images via PyTorch. See VGG16 diagram below, as well as torch model summary.\n",
        "\n",
        "![AlexNet Architecture](torch/VGG16_architecture.png)\n"
      ],
      "id": "87a94848"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# load trained torch model\n",
        "model = VGG16_pretrained(num_classes=2).to(device)\n",
        "model.load(input_fpath=cons.torch_model_pt_fpath)\n",
        "# print model summary\n",
        "print(model)"
      ],
      "id": "504c7d94",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance\n",
        "\n",
        "The model was trained across 4 epochs. The model accuracy and loss are plotted below across the training and validation sets.\n",
        "\n",
        "![Model Accuracy](torch/model_accuracy.png)\n",
        "\n",
        "![Model Loss](torch/model_loss.png)\n",
        "\n",
        "## Model Image Predictions\n",
        "\n",
        "The model predictions were made for the Kaggle test set, see below example model predictions.\n",
        "\n",
        "![Predicted Images](report/torch/pred_images.jpg)"
      ],
      "id": "51886ec7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}