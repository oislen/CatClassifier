{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3dd7e904",
      "metadata": {},
      "source": [
        "# Cats vs Dogs Image Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9e032473",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"../model\")\n",
        "import cons\n",
        "\n",
        "import torch\n",
        "from model.torch.VGG16_pretrained import VGG16_pretrained"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a94848",
      "metadata": {},
      "source": [
        "This project aims to create a model to classify cat and dog images. The data was sourced from the [dogs-vs-cats](https://www.kaggle.com/competitions/dogs-vs-cats/overview) Kaggle competition, and also from [freeimages.com](https://www.freeimages.com/) using a web scraper. Docker containers were used to deploy the application on an EC2 spot instances in order to scale up hardware and computation power. \n",
        "\n",
        "## Example Image\n",
        "\n",
        "![Random Image](torch/random_image.jpg)\n",
        "\n",
        "## Data Processing\n",
        "\n",
        "The images were resized to a uniform dimension and the colour channels normalised prior to the modelling training phase. See example image processing below. \n",
        "\n",
        "![Generator Plot](torch/generator_plot.jpg)\n",
        "\n",
        "## VGG16 Model Architecture\n",
        "\n",
        "A pre-trained VGG CNN model with 16 layers was trained using the processed images via PyTorch. See VGG16 diagram below, as well as torch model summary. Stochastic gradient descent was implemented to optimize the training criterion function cross entropy loss.\n",
        "\n",
        "![AlexNet Architecture](torch/VGG16_architecture.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "504c7d94",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG16_pretrained(\n",
            "  (resnet): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): ReLU(inplace=True)\n",
            "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (15): ReLU(inplace=True)\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (18): ReLU(inplace=True)\n",
            "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (20): ReLU(inplace=True)\n",
            "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (22): ReLU(inplace=True)\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (25): ReLU(inplace=True)\n",
            "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (27): ReLU(inplace=True)\n",
            "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (29): ReLU(inplace=True)\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (classifier): Sequential(\n",
            "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Dropout(p=0.5, inplace=False)\n",
            "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1000, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() and cons.check_gpu else 'cpu')\n",
        "# load trained torch model\n",
        "model = VGG16_pretrained(num_classes=2).to(device)\n",
        "model.load(input_fpath=cons.torch_model_pt_fpath)\n",
        "# print model summary\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51886ec7",
      "metadata": {},
      "source": [
        "## Model Performance\n",
        "\n",
        "The model was trained across 10 epochs. Learning rate reduction on plateau and early stopping were implemented as part of training procedure. The model accuracy and loss are plotted below across the training and validation sets.\n",
        "\n",
        "![Model Accuracy](torch/model_accuracy.png)\n",
        "\n",
        "![Model Loss](torch/model_loss.png)\n",
        "\n",
        "## Model Image Predictions\n",
        "\n",
        "The model predictions were made for the Kaggle test set, see below example model predictions.\n",
        "\n",
        "![Predicted Images](torch/pred_images.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c7419e8",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "catclass",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
